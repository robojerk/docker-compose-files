# Configurations for hardware-accelerated machine learning

# If using Unraid or another platform that doesn't allow multiple Compose files,
# you can inline the config for a backend by copying its contents
# into the immich-machine-learning service in the docker-compose.yml file.

# See https://immich.app/docs/features/ml-hardware-acceleration for info on usage.

services:
  cpu: {}

  openvino:
    devices:
      - /dev/dri:/dev/dri
    environment:
      - OPENVINO_DEVICE=GPU
      - OPENVINO_GPU_DEVICE_ID=0
      - INTEL_MEDIA_VA_DRIVER_PATH=/usr/lib/x86_64-linux-gnu/dri
      - LIBVA_DRIVER_NAME=iHD
      - LIBVA_DRIVERS_PATH=/usr/lib/x86_64-linux-gnu/dri
